import json
import os
import pickle
from typing import List

import pandas as pd
from comet_ml.api import API
from loguru import logger as logging
from pydantic import BaseModel

from src.data_preprocessing import interpolate_missing_candles
from src.feature_engineering import add_features
from src.utils import get_model_name
from tools.ohlc_data_reader import OHLCDataReader


class PredictorOutput(BaseModel):
    """
    A pydantic model that represents the output of the predictor
    """

    price_change_prediction: float
    price_prediction: float
    current_price: float
    product_id: str
    current_ts_ms: int
    current_ts: str
    predicted_ts: str

    # A method that returns the prediction as a dictionary
    def to_dict(self):
        return {
            'price_change_prediction': self.price_change_prediction,
            'price_prediction': self.price_prediction,
            'current_price': self.current_price,
            'product_id': self.product_id,
            'current_ts_ms': self.current_ts_ms,
            'current_ts': self.current_ts,
            'predicted_ts': self.predicted_ts,
        }


class Predictor:
    def __init__(
        self,
        model_path: str,
        ohlc_window_sec: int,
        feature_view_name: str,
        feature_view_version: int,
        product_id: str,
        last_n_minutes: int,
        features_to_use: List[str],
        prediction_window_sec: int,
    ):
        self.model = self._load_model_pickle(model_path)

        self.ohlc_data_reader = OHLCDataReader(
            feature_view_name=feature_view_name,
            feature_view_version=feature_view_version,
            ohlc_window_sec=ohlc_window_sec,
        )

        self.ohlc_window_sec = ohlc_window_sec
        self.product_id = product_id
        self.last_n_minutes = last_n_minutes
        self.features_to_use = features_to_use
        self.prediction_window_sec = prediction_window_sec

    @classmethod
    def from_model_registry(
        cls,
        product_id: str,
        status: str,
    ) -> 'Predictor':
        """
        Fetches the model artifact from the model, and all relevant metadata to make
        predictions from the model artifact, and returms a Predictor object

        # Steps:
        Fetch the model artifact from the model registry
        Fetch the relevant metadata from the model registry
        Return a Predictor object with the model artifact and metadata

        Args:
            product_id (str): Product ID
            status (str): Status of the model

        Returns:
            Predictor: An a instance of the predictor class with the model artifact and metadata
                fetched from the model registry
        """
        comet_api = API(api_key=os.environ['COMET_ML_API_KEY'])

        # Step 1: Download the model artifact from the model registry
        model = comet_api.get_model(
            workspace=os.environ['COMET_ML_WORKSPACE'],
            model_name=get_model_name(product_id),
        )

        # Find the version for the current model with the given status
        model_versions = model.find_versions(status=status)

        # Sort the model versions list from high to low to pick the latest version
        model_version = sorted(model_versions, reverse=True)[0]

        # Download the model artifact for this `model_version`
        model.download(version=model_version, output_folder='./')

        # This name is generated by the same function called in training pipeline
        model_path = './xgboost_model.pkl'

        # Step 2: Fetch the metadata from the model registry
        # Find the experiment associated with the model
        experiment_key = model.get_details(version=model_version)['experimentKey']

        # Fetch the experiment
        experiment = comet_api.get_experiment_by_key(experiment_key)

        # Fetch all the parameters from the experiment
        # - ohlc_window_sec: int
        # - feature_view_name: str
        # - feature_view_version: int
        # - product_id: str
        # - last_n_minutes: int
        # - features_to_use: List[str]
        # - prediction_window_sec: int
        ohlc_window_sec = int(
            experiment.get_parameters_summary('ohlc_window_sec')['valueCurrent']
        )
        feature_view_name = experiment.get_parameters_summary('feature_view_name')[
            'valueCurrent'
        ]
        feature_view_version = int(
            experiment.get_parameters_summary('feature_view_version')['valueCurrent']
        )
        product_id = experiment.get_parameters_summary('product_id')['valueCurrent']

        last_n_minutes = 30  # int(experiment.get_parameters_summary('last_n_minutes')['valueCurrent'])

        # Fetch the features to use. It is a list of strings and needs to parsed
        features_to_use = json.loads(
            experiment.get_parameters_summary('features_to_use')['valueCurrent']
        )
        prediction_window_sec = int(
            experiment.get_parameters_summary('prediction_window_sec')['valueCurrent']
        )

        # Step 3: Return a Predictor object with the model artifact and metadata
        return cls(
            model_path=model_path,
            ohlc_window_sec=ohlc_window_sec,
            feature_view_name=feature_view_name,
            feature_view_version=feature_view_version,
            product_id=product_id,
            last_n_minutes=last_n_minutes,
            features_to_use=features_to_use,
            prediction_window_sec=prediction_window_sec,
        )

    def predict(self) -> PredictorOutput:
        """
        Generates a prediction using the model in 'self.model' and the latest data from the feature store.

        Steps: Need to follow the same preprocessing steps as in training pipeline
            Fetch the latest OHLC data from the feature store
            Preprocess the data (interpolate missing candles)
            model.predict(X) where X is the preprocessed data

        Returns:
            PredictorOutput: A pydantic model that represents the output of the predictor
        """
        # Step 1: Fetch the latest OHLC data from the feature store
        logging.info('Fetching t OHLC data from the online feature store')
        ohlc_data = self.ohlc_data_reader.read_from_online_store(
            product_id=self.product_id, last_n_minutes=self.last_n_minutes
        )
        ohlc_data['datetime'] = pd.to_datetime(ohlc_data['timestamp'], unit='ms')

        # Step 2: Preprocess the data
        logging.info('Preprocessing the OHLC data - interpolating missing candles')
        ohlc_data = interpolate_missing_candles(ohlc_data, self.ohlc_window_sec)

        logging.info('Preprocessing the OHLC data - adding features')
        n_candles_into_future = self.prediction_window_sec // self.ohlc_window_sec
        ohlc_data = add_features(
            X=ohlc_data, n_candles_into_future=n_candles_into_future
        )

        logging.info(
            "Preprocessing the OHLC data - keping features in 'self.features_to_use'"
        )
        X = ohlc_data[self.features_to_use]

        # Step 3: Model prediction
        logging.info('Running inference on the preprocessed data')
        price_change_prediction = self.model.predict(X)[-1]

        # Get the current price
        current_price = ohlc_data['close'].iloc[-1]

        # Compute the predicted price
        price_prediction = current_price * (1 + price_change_prediction)

        # Get the element from the prediction array and create a PredictorOutput object with the predciton,
        # product_id, and the last timestamp of the candle
        current_ts_ms = ohlc_data['timestamp'].iloc[-1]

        predicted_ts_ms = current_ts_ms + self.prediction_window_sec * 1000

        # Transform the timestamps to datetime strings in UTC for better readability
        current_ts = pd.to_datetime(current_ts_ms, unit='ms').strftime(
            '%Y-%m-%d %H:%M:%S'
        )
        predicted_ts = pd.to_datetime(predicted_ts_ms, unit='ms').strftime(
            '%Y-%m-%d %H:%M:%S'
        )

        return PredictorOutput(
            price_change_prediction=price_change_prediction,
            price_prediction=price_prediction,
            current_price=current_price,
            product_id=self.product_id,
            current_ts_ms=current_ts_ms,
            current_ts=current_ts,
            predicted_ts=predicted_ts,
        )

    def _load_model_pickle(self, model_path: str):
        """
        Loads the model from a pickle file

        Args:
            model_path (str): Path to the model pickle file

        Returns:
            model: A trained model
        """
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        return model


if __name__ == '__main__':
    logging.info('Running the predictor class with the from_model_registry method')
    predictor = Predictor.from_model_registry(
        product_id='BTC/USD',
        status='production',
    )
    prediction = predictor.predict()
    logging.info(f'Prediction: {prediction}')
